# MEDICORE â€” Complete Project Architecture

> A clinical medical information assistant powered by RAG (Retrieval-Augmented Generation),
> built with FastAPI, React, MongoDB, Pinecone, and Groq LLaMA 3.1.

---

## Table of Contents

1. [High-Level Architecture Diagram](#1-high-level-architecture-diagram)
2. [How the System Works â€” End-to-End Flow](#2-how-the-system-works--end-to-end-flow)
3. [Tech Stack](#3-tech-stack)
4. [Project Directory Structure](#4-project-directory-structure)
5. [Backend â€” File-by-File Description](#5-backend--file-by-file-description)
6. [Frontend â€” File-by-File Description](#6-frontend--file-by-file-description)
7. [Data Ingestion Pipeline](#7-data-ingestion-pipeline)
8. [MongoDB Collections](#8-mongodb-collections)
9. [API Endpoint Reference](#9-api-endpoint-reference)
10. [Environment Variables](#10-environment-variables)
11. [Key Design Decisions](#11-key-design-decisions)

---

## 1. High-Level Architecture Diagram

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         USER'S BROWSER                                       â•‘
â•‘                                                                              â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘   â”‚                    REACT FRONTEND (Vite + JSX)                       â”‚   â•‘
â•‘   â”‚                     http://localhost:5173                            â”‚   â•‘
â•‘   â”‚                                                                      â”‚   â•‘
â•‘   â”‚  AuthScreen â”€â”€â–º App.jsx (root state) â”€â”€â–º Sidebar                    â”‚   â•‘
â•‘   â”‚                     â”‚                                                â”‚   â•‘
â•‘   â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â•‘
â•‘   â”‚            â”‚         â”‚                             â”‚                â”‚   â•‘
â•‘   â”‚       ChatInput  ChatMessage               HealthProfileForm        â”‚   â•‘
â•‘   â”‚       VoiceCtrl  TriageBadge               SymptomChecker           â”‚   â•‘
â•‘   â”‚       LangSel    ConfidenceBadge           LabUploadModal           â”‚   â•‘
â•‘   â”‚       ExportPDF  FeedbackButtons                                    â”‚   â•‘
â•‘   â”‚                                                                      â”‚   â•‘
â•‘   â”‚                    services/api.js (axios + fetch SSE)               â”‚   â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              â”‚  HTTP / SSE  (port 8000)
                              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      FASTAPI BACKEND (Python)                                â•‘
â•‘                       http://localhost:8000                                  â•‘
â•‘                                                                              â•‘
â•‘   main.py                                                                    â•‘
â•‘   â”œâ”€â”€ CORS Middleware                                                        â•‘
â•‘   â”œâ”€â”€ Rate Limiter (slowapi)                                                 â•‘
â•‘   â””â”€â”€ /api  â”€â”€â–º  chat.py (APIRouter)                                        â•‘
â•‘                      â”‚                                                       â•‘
â•‘        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â•‘
â•‘        â”‚             â”‚                                       â”‚               â•‘
â•‘   [AUTH]         [CHAT FLOW]                          [PROFILE/MISC]         â•‘
â•‘  /auth/signup   POST /chat  â”€â”€â”€â”€ safety.py            POST /profile          â•‘
â•‘  /auth/login    POST /chat/stream â”€â”€ triage.py        GET  /profile          â•‘
â•‘  /auth/logout   POST /chat/image                      POST /simplify         â•‘
â•‘                 POST /chat/lab-results                POST /translate        â•‘
â•‘                 GET  /chat/history                    POST /feedback         â•‘
â•‘                 GET  /chat/{id}                                              â•‘
â•‘                 DELETE /chat/{id}                                            â•‘
â•‘                                                                              â•‘
â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘
â•‘   â”‚                     SERVICE LAYER                                    â”‚   â•‘
â•‘   â”‚                                                                      â”‚   â•‘
â•‘   â”‚  llm.py          retriever.py      hybrid_retriever.py               â”‚   â•‘
â•‘   â”‚  (Groq LLaMA)    (Pinecone vec)    (BM25 + RRF + reranker)          â”‚   â•‘
â•‘   â”‚                                                                      â”‚   â•‘
â•‘   â”‚  live_context.py                   lab_reference.py                  â”‚   â•‘
â•‘   â”‚  (PubMed/RxNorm/FDA)               (30+ lab ranges + parser)         â”‚   â•‘
â•‘   â”‚                                                                      â”‚   â•‘
â•‘   â”‚  auth.py          database.py                                        â”‚   â•‘
â•‘   â”‚  (JWT/bcrypt)     (Motor/MongoDB Atlas)                              â”‚   â•‘
â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            â”‚                  â”‚                         â”‚
            â–¼                  â–¼                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  MONGODB     â”‚  â”‚    PINECONE      â”‚   â”‚   EXTERNAL APIs      â”‚
    â”‚  Atlas       â”‚  â”‚  Vector Store    â”‚   â”‚                      â”‚
    â”‚              â”‚  â”‚  (medicore-ai)   â”‚   â”‚  PubMed E-utilities  â”‚
    â”‚  users       â”‚  â”‚                  â”‚   â”‚  RxNorm interactions â”‚
    â”‚  chats       â”‚  â”‚  ~500K+ chunks   â”‚   â”‚  OpenFDA events      â”‚
    â”‚  chat_summ.  â”‚  â”‚  PubMedBERT      â”‚   â”‚  (2.5s timeout)      â”‚
    â”‚  health_prof â”‚  â”‚  embeddings      â”‚   â”‚                      â”‚
    â”‚  feedback    â”‚  â”‚  (768-dim)       â”‚   â”‚  Groq API            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  (LLaMA 3.1 8B)      â”‚
                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. How the System Works â€” End-to-End Flow

### 2a. Authentication Flow

```
User opens app
      â”‚
      â–¼
AuthScreen.jsx  â”€â”€  login / signup form
      â”‚
      â–¼
api.js:login()  â”€â”€â–º  POST /api/auth/login
                            â”‚
                     chat.py:login()
                            â”‚
                     MongoDB: find user by email
                            â”‚
                     auth.py:verify_password()  (bcrypt check)
                            â”‚
                     auth.py:create_access_token()  (JWT, 24h expiry)
                            â”‚
                     â—„â”€â”€ { access_token, user }
      â”‚
      â–¼
localStorage.setItem("medicore_token", ...)
App.jsx state: user = { id, email, name }
All future API calls: Authorization: Bearer <JWT>
```

---

### 2b. Main Chat Flow (Two-Turn RAG)

```
User types a message (e.g., "my stomach hurts")
      â”‚
      â–¼
App.jsx:handleSendMessage()
      â”‚
      â”œâ”€â”€ [if non-English language selected]
      â”‚       api.js:detectLanguage()  â†’  POST /api/detect-language
      â”‚       api.js:translateText()   â†’  POST /api/translate   (to English)
      â”‚
      â–¼
api.js:sendMessageStream()  â”€â”€â–º  POST /api/chat/stream  (SSE)
                                          â”‚
                                  chat.py:chat_stream()
                                          â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚      SAFETY GATE           â”‚
                            â”‚   safety.py:              â”‚
                            â”‚   validate_message_async() â”‚
                            â”‚                            â”‚
                            â”‚   Tier 1: keyword scan     â”‚
                            â”‚   (50+ emergency terms)    â”‚
                            â”‚         â”‚                  â”‚
                            â”‚   Tier 2: LLM context      â”‚
                            â”‚   (is it ACTIVE emergency?)â”‚
                            â”‚         â”‚                  â”‚
                            â”‚   Mental health check      â”‚
                            â”‚   (adds supportive msg)    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚    TURN 1: SPECIFICITY     â”‚
                            â”‚                            â”‚
                            â”‚  llm.py:                   â”‚
                            â”‚  assess_query_specificity()â”‚
                            â”‚                            â”‚
                            â”‚  LLaMA judges:             â”‚
                            â”‚  "stomach hurts" â†’ VAGUE   â”‚
                            â”‚  â†’ generate follow-up Q    â”‚
                            â”‚                            â”‚
                            â”‚  "What is diabetes?" â†’     â”‚
                            â”‚  SPECIFIC â†’ skip to RAG    â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                              [if SPECIFIC or Turn 2]
                                          â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚      QUERY REFORMULATION   â”‚
                            â”‚                            â”‚
                            â”‚  llm.py:                   â”‚
                            â”‚  reformulate_for_retrieval()â”‚
                            â”‚                            â”‚
                            â”‚  "stomach hurts after food"â”‚
                            â”‚  â†’ "abdominal pain         â”‚
                            â”‚    epigastric dyspepsia    â”‚
                            â”‚    gastritis gallbladder"  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚     HYBRID RETRIEVAL       â”‚
                            â”‚                            â”‚
                            â”‚  hybrid_retriever.py:      â”‚
                            â”‚  hybrid_search(query, k=5) â”‚
                            â”‚                            â”‚
                            â”‚  Step 1: Pinecone vector   â”‚
                            â”‚  search (PubMedBERT,       â”‚
                            â”‚  768-dim embeddings)       â”‚
                            â”‚  â†’ top 15 candidates       â”‚
                            â”‚                            â”‚
                            â”‚  Step 2: BM25 keyword      â”‚
                            â”‚  search on those 15 docs   â”‚
                            â”‚                            â”‚
                            â”‚  Step 3: Reciprocal Rank   â”‚
                            â”‚  Fusion (60% vec, 40% BM25)â”‚
                            â”‚                            â”‚
                            â”‚  Step 4: Cross-encoder     â”‚
                            â”‚  reranking (MiniLM-L6-v2)  â”‚
                            â”‚  â†’ final top 5 chunks      â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚     LIVE CONTEXT (async)   â”‚
                            â”‚                            â”‚
                            â”‚  live_context.py:          â”‚
                            â”‚  get_live_context()        â”‚
                            â”‚                            â”‚
                            â”‚  Concurrent (2.5s max):    â”‚
                            â”‚  â€¢ PubMed recent abstracts â”‚
                            â”‚  â€¢ RxNorm drug interactionsâ”‚
                            â”‚  â€¢ OpenFDA adverse events  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚      TRIAGE ASSESSMENT     â”‚
                            â”‚                            â”‚
                            â”‚  triage.py:                â”‚
                            â”‚  assess_triage_level()     â”‚
                            â”‚                            â”‚
                            â”‚  LLaMA classifies:         â”‚
                            â”‚  ğŸ”´ Emergency              â”‚
                            â”‚  ğŸŸ  Urgent (<24h)          â”‚
                            â”‚  ğŸŸ¡ Semi-urgent (1-3 days) â”‚
                            â”‚  ğŸŸ¢ Routine                â”‚
                            â”‚  ğŸ”µ Informational          â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚     LLM RESPONSE GEN       â”‚
                            â”‚                            â”‚
                            â”‚  llm.py:                   â”‚
                            â”‚  generate_response_stream()â”‚
                            â”‚                            â”‚
                            â”‚  System prompt: MediCore   â”‚
                            â”‚  identity + formatting     â”‚
                            â”‚  rules + clinical approach â”‚
                            â”‚                            â”‚
                            â”‚  User message includes:    â”‚
                            â”‚  â€¢ Original query          â”‚
                            â”‚  â€¢ Follow-up answer        â”‚
                            â”‚  â€¢ Health profile (if set) â”‚
                            â”‚  â€¢ Session memory (3 prev) â”‚
                            â”‚  â€¢ RAG context chunks      â”‚
                            â”‚  â€¢ Live context            â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                              SSE stream: token by token
                                          â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚     PERSIST & MEMORY       â”‚
                            â”‚                            â”‚
                            â”‚  MongoDB: save messages    â”‚
                            â”‚                            â”‚
                            â”‚  Background task:          â”‚
                            â”‚  summarize conversation    â”‚
                            â”‚  â†’ store in chat_summaries â”‚
                            â”‚  (used for next session)   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                                   Frontend renders:
                                   â€¢ Streaming text
                                   â€¢ Triage badge (color)
                                   â€¢ Confidence indicator
                                   â€¢ Sources snippets
                                   â€¢ Simplify button
                                   â€¢ Find Hospitals button
```

---

### 2c. Image Analysis Flow

```
User uploads medical image
      â”‚
      â–¼
App.jsx:handleSendWithImage()
      â”‚
      â–¼
api.js:sendImageMessage()  â”€â”€â–º  POST /api/chat/image  (multipart)
                                        â”‚
                                chat.py:chat_image()
                                        â”‚
                         Step 1: llm.py:describe_image()
                                 Model: llama-4-scout-17b (vision)
                                 â†’ clinical description text
                                        â”‚
                         Step 2: combined_query =
                                 user_message + image_description
                                        â”‚
                         Step 3: reformulate_for_retrieval()
                                        â”‚
                         Step 4: hybrid_search() â†’ RAG chunks
                                        â”‚
                         Step 5: generate_response() with context
                                        â”‚
                                 â—„â”€â”€ structured medical response
```

---

### 2d. Lab Results Flow

```
User uploads lab report (PDF or image)
      â”‚
      â–¼
LabUploadModal (user adds context notes)
      â”‚
      â–¼
api.js:sendLabResults()  â”€â”€â–º  POST /api/chat/lab-results
                                        â”‚
                              chat.py:chat_lab_results()
                                        â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  PDF?                                   â”‚  Image?
                    â–¼                                         â–¼
           fitz (PyMuPDF) text extract           llm:describe_image()
           â†’ if <50 chars (scanned):             structured extraction
             vision model fallback               prompt: "TEST VALUE UNIT"
                    â”‚                                         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                        lab_reference.py:parse_lab_text()
                        â†’ regex parse each line
                        â†’ normalize test name (aliases)
                        â†’ classify: normal/high/low/critical
                                   â”‚
                        format_lab_table_as_context()
                        â†’ structured table for LLM
                                   â”‚
                        hybrid_search() â†’ RAG context
                                   â”‚
                        generate_response()
                        â†’ medical interpretation
                                   â”‚
                    â—„â”€â”€ { lab_values[], interpretation, sources }
                                   â”‚
                    Frontend: lab value table + colored status badges
```

---

## 3. Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| Frontend framework | React 18 + Vite | SPA with fast HMR |
| HTTP client | Axios + native Fetch | REST calls + SSE streaming |
| Backend framework | FastAPI 0.110 | Async REST API |
| ASGI server | Uvicorn | Production-grade async server |
| LLM provider | Groq (LLaMA 3.1 8B Instant) | Text generation, classification |
| Vision model | Llama-4-Scout-17B (via Groq) | Medical image description |
| Embeddings | PubMedBERT (HuggingFace) | Medical-optimized 768-dim vectors |
| Vector store | Pinecone (serverless) | Approximate nearest neighbor search |
| Keyword search | BM25 (rank-bm25) | Exact term matching |
| Reranker | cross-encoder/ms-marco-MiniLM-L-6-v2 | Final relevance scoring |
| Database | MongoDB Atlas (Motor async) | Users, chats, profiles, feedback |
| Auth | JWT (python-jose) + bcrypt (passlib) | Stateless auth with 24h tokens |
| Rate limiting | slowapi | Per-IP endpoint throttling |
| Live data | PubMed + RxNorm + OpenFDA | Real-time medical evidence |
| PDF processing | PyMuPDF (fitz) | Text extraction + scanned-page render |
| Validation | Pydantic v2 | Request/response schemas |

---

## 4. Project Directory Structure

```
Medicore/
â”‚
â”œâ”€â”€ .gitignore                    â† Git exclusions (env, dist, .vs, PDFs, etc.)
â”œâ”€â”€ ARCHITECTURE.md               â† This file
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                   â† FastAPI app entry point, lifespan startup
â”‚   â”œâ”€â”€ requirements.txt          â† All Python dependencies (pinned)
â”‚   â”œâ”€â”€ .env                      â† Secrets (never committed)
â”‚   â”œâ”€â”€ .env.example              â† Template for required env vars
â”‚   â”‚
â”‚   â”œâ”€â”€ app/                      â† Core application package
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat.py               â† ALL API endpoints + request/response models
â”‚   â”‚   â”œâ”€â”€ llm.py                â† Groq LLM service (all LLM interactions)
â”‚   â”‚   â”œâ”€â”€ retriever.py          â† Pinecone vector store service
â”‚   â”‚   â”œâ”€â”€ hybrid_retriever.py   â† BM25 + RRF + cross-encoder reranker
â”‚   â”‚   â”œâ”€â”€ live_context.py       â† PubMed / RxNorm / OpenFDA real-time data
â”‚   â”‚   â”œâ”€â”€ lab_reference.py      â† Lab normal ranges + text parser
â”‚   â”‚   â”œâ”€â”€ safety.py             â† Emergency detection + content moderation
â”‚   â”‚   â”œâ”€â”€ triage.py             â† Clinical urgency classifier (5 levels)
â”‚   â”‚   â”œâ”€â”€ auth.py               â† Password hashing + JWT token creation
â”‚   â”‚   â””â”€â”€ database.py           â† MongoDB Atlas connection (Motor async)
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                â† One-time data pipeline (run before launch)
â”‚   â”‚   â”œâ”€â”€ rag_setup.py          â† PDF â†’ chunks â†’ embeddings â†’ Pinecone upload
â”‚   â”‚   â”œâ”€â”€ fetch_web_sources.py  â† Optional: scrape WHO/CDC web content
â”‚   â”‚   â””â”€â”€ data/pdfs/            â† 5 volumes of Gale Encyclopedia of Medicine
â”‚   â”‚                                (ignored by git â€” already in Pinecone)
â”‚   â”‚
â”‚   â”œâ”€â”€ test_api.py               â† Manual HTTP smoke tests for chat endpoints
â”‚   â””â”€â”€ test_api_auth.py          â† Manual HTTP smoke tests for auth endpoints
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                â† Vite HTML entry point
â”‚   â”œâ”€â”€ vite.config.js            â† Vite config (proxy â†’ localhost:8000)
â”‚   â”œâ”€â”€ package.json              â† Node dependencies
â”‚   â”œâ”€â”€ .env                      â† VITE_API_URL (never committed)
â”‚   â”œâ”€â”€ .env.example              â† Template
â”‚   â”‚
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ medical-icon.svg      â† Favicon / PWA icon
â”‚   â”‚
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.jsx              â† React root mount
â”‚       â”œâ”€â”€ App.jsx               â† Root component, all state, all handlers
â”‚       â”‚
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ AuthScreen.jsx    â† Login / Signup form
â”‚       â”‚   â”œâ”€â”€ Sidebar.jsx       â† Chat history list + user info
â”‚       â”‚   â”œâ”€â”€ ChatMessage.jsx   â† Single message renderer (markdown, badges)
â”‚       â”‚   â”œâ”€â”€ ChatInput.jsx     â† Text input field with keyboard shortcuts
â”‚       â”‚   â”œâ”€â”€ VoiceControls.jsx â† Web Speech API for voice input
â”‚       â”‚   â”œâ”€â”€ LoadingSpinner.jsxâ† Animated loading indicator
â”‚       â”‚   â”œâ”€â”€ LanguageSelector.jsx â† Dropdown for 12 languages
â”‚       â”‚   â”œâ”€â”€ HealthProfileForm.jsx â† Modal for user health data
â”‚       â”‚   â”œâ”€â”€ SymptomChecker.jsx   â† Guided symptom input wizard
â”‚       â”‚   â”œâ”€â”€ LabUploadModal.jsx   â† Modal: context notes before lab upload
â”‚       â”‚   â”œâ”€â”€ ExportChatPDF.jsx    â† Download conversation as PDF
â”‚       â”‚   â”œâ”€â”€ TriageBadge.jsx      â† Color-coded urgency display
â”‚       â”‚   â”œâ”€â”€ ConfidenceBadge.jsx  â† RAG confidence display
â”‚       â”‚   â””â”€â”€ FeedbackButtons.jsx  â† Thumbs up/down on responses
â”‚       â”‚
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â””â”€â”€ api.js            â† All API calls (axios + SSE fetch)
â”‚       â”‚
â”‚       â””â”€â”€ styles/
â”‚           â”œâ”€â”€ App.css           â† Main layout + chat styles
â”‚           â”œâ”€â”€ AuthScreen.css    â† Login/signup card styles
â”‚           â””â”€â”€ Sidebar.css       â† Sidebar panel styles
```

---

## 5. Backend â€” File-by-File Description

---

### `backend/main.py`
**Role:** Application entry point. Creates and configures the FastAPI app.

**What it does:**
- Loads `.env` with `python-dotenv`
- Registers the `lifespan` async context manager that runs **on startup**:
  1. Connects to MongoDB Atlas (`db_service.connect()`)
  2. Pings MongoDB to verify connectivity
  3. Initializes the Pinecone vector store (`retriever_service.initialize()`)
  4. Initializes the hybrid retriever and loads the cross-encoder model (`hybrid_retriever_service.initialize()`)
- On **shutdown**: closes the MongoDB connection cleanly
- Configures CORS to allow requests from `localhost:5173` (Vite) and `localhost:3000`
- Registers `slowapi` rate limiter globally
- Mounts all routes under `/api` prefix
- Provides `/` (info) and `/health` endpoints

---

### `backend/app/chat.py`
**Role:** The central hub â€” all API endpoints + Pydantic models.

**Pydantic models defined here:**
- `SignupRequest`, `LoginRequest`, `AuthResponse` â€” auth
- `ChatRequest`, `ChatResponse`, `NewChatResponse` â€” chat I/O
- `ChatHistoryItem`, `ChatHistoryResponse`, `ChatDetailResponse` â€” history
- `HealthProfileRequest`, `HealthProfileResponse` â€” user profile
- `LabValue`, `LabResultResponse` â€” lab results
- `SimplifyRequest`, `TranslateRequest`, `FeedbackRequest` â€” utilities

**Auth helpers:**
- `get_current_user()` â€” FastAPI dependency: decodes JWT, returns `user_id`. Raises 401 if invalid.
- `get_optional_user()` â€” Same but returns `None` instead of raising, for endpoints that work both authenticated and anonymous.

**Session memory helpers:**
- `get_session_summaries(user_id)` â€” Fetches last 3 conversation summaries from `chat_summaries` collection to give the LLM cross-session context.
- `summarize_and_store_chat(chat_id, user_id, messages)` â€” Called as a background `asyncio.Task` after each response; uses the LLM to write a short summary of the conversation and stores it.

**API endpoints (18 total):**

| Method | Path | Auth | Rate Limit | Description |
|--------|------|------|------------|-------------|
| POST | /auth/signup | No | 5/min | Register new user |
| POST | /auth/login | No | 10/min | Login, returns JWT |
| POST | /auth/logout | Yes | â€” | Logs out (client deletes token) |
| POST | /chat/new | Yes | â€” | Create empty chat session |
| GET | /chat/history | Yes | â€” | List all user's chats |
| GET | /chat/{id} | Yes | â€” | Full message list for one chat |
| DELETE | /chat/{id} | Yes | â€” | Delete a chat |
| POST | /chat | Optional | 20/min | Two-turn RAG (non-streaming) |
| POST | /chat/stream | Optional | 20/min | Two-turn RAG (SSE streaming) |
| POST | /chat/image | Optional | 10/min | Medical image analysis |
| POST | /chat/lab-results | Optional | 5/min | Lab report interpretation |
| POST | /simplify | Optional | â€” | Simplify last assistant response |
| POST | /translate | Yes | â€” | Translate text to target language |
| POST | /detect-language | Yes | â€” | Detect language of text |
| POST | /profile | Yes | â€” | Create/update health profile |
| GET | /profile | Yes | â€” | Get health profile |
| DELETE | /profile | Yes | â€” | Delete health profile |
| POST | /feedback | Yes | â€” | Submit thumbs up/down |

**Two-turn conversation logic (POST /chat and POST /chat/stream):**
1. Safety validation (emergency, inappropriate content, mental health)
2. If `awaiting_followup=False`: ask LLM to assess query specificity
   - Vague â†’ generate one focused follow-up question â†’ return with `awaiting_followup=True`
   - Specific â†’ go directly to RAG pipeline
3. If `awaiting_followup=True` (Turn 2): combine original query + user's follow-up answer â†’ RAG
4. RAG pipeline: reformulate query â†’ hybrid search â†’ live context â†’ generate response
5. Assess triage level (runs concurrently)
6. Save messages to MongoDB
7. Background task: summarize and store for cross-session memory

---

### `backend/app/llm.py`
**Role:** All LLM interactions via the Groq API.

**Primary model:** `llama-3.1-8b-instant` â€” fast, 128K context, medical-capable.
**Vision model:** `meta-llama/llama-4-scout-17b-16e-instruct` â€” used only for image description.

**Methods:**

| Method | Purpose | Tokens | Temp |
|--------|---------|--------|------|
| `assess_query_specificity()` | Returns `True` if follow-up needed | 10 | 0.1 |
| `reformulate_for_retrieval()` | Converts natural query to medical search terms | 100 | 0.1 |
| `generate_followup()` | Generates one clinical clarifying question | 100 | 0.5 |
| `generate_response()` | Main RAG response (non-streaming) | 1500 | 0.7 |
| `generate_response_stream()` | Same but yields chunks via SSE | 1500 | 0.7 |
| `describe_image()` | Clinical image description for vision model | 300 | 0.3 |
| `simplify_text()` | Rewrites response in plain language | 500 | 0.5 |
| `translate_text()` | Translates to target language (12 languages) | 3000 | 0.3 |
| `detect_language()` | Returns ISO language code | 10 | 0.1 |
| `summarize_conversation()` | 2-3 sentence session summary for memory | 200 | 0.3 |

**Key implementation detail:** Groq's Python client is synchronous. All calls are wrapped with `asyncio.to_thread()` to avoid blocking the async FastAPI event loop. Streaming uses a `queue.Queue` + background thread pattern to bridge the sync Groq stream into an async generator.

**System prompt (in `_get_system_prompt()`):** The MediCore identity and all response formatting rules are defined here. The prompt enforces:
- Context-only answers (no hallucination)
- No diagnosis, no specific dosages
- Adaptive format per query type (symptom / condition / medication / general)
- Mandatory educational disclaimer at the end

---

### `backend/app/retriever.py`
**Role:** Pinecone vector store service. Pure semantic similarity search.

**Embedding model:** `pritamdeka/S-PubMedBert-MS-MARCO` (768-dimensional, medical-domain-tuned). **Must match the model used during ingestion in `rag_setup.py`.**

**Methods:**
- `initialize()` â€” Loads the HuggingFace embedding model and connects to the Pinecone index. Verifies the index exists (fails clearly if `rag_setup.py` was never run).
- `search(query, k=5)` â€” Async similarity search, returns list of text strings.
- `search_with_scores(query, k=5)` â€” Returns chunks with cosine similarity scores + confidence level (`high` > 0.8, `medium` > 0.5, `low` otherwise).
- `search_sync(query, k=5)` â€” Synchronous fallback.
- `get_retriever(k=5)` â€” Returns a LangChain retriever interface (used internally).

**Singleton:** `retriever_service = RetrieverService()` â€” one instance shared across all requests.

---

### `backend/app/hybrid_retriever.py`
**Role:** Combines vector search + BM25 + cross-encoder for higher quality retrieval.

**Pipeline for each query:**
1. **Vector search** (via `retriever_service`): fetch `k Ã— 3 = 15` candidates with scores
2. **BM25**: build an in-memory BM25 index from those 15 docs, compute keyword scores
3. **Reciprocal Rank Fusion (RRF)**: merge vector ranks (weight 0.6) and BM25 ranks (weight 0.4) using the formula `score = weight / (60 + rank)`
4. **Cross-encoder reranking**: `cross-encoder/ms-marco-MiniLM-L-6-v2` scores each (query, document) pair â†’ sort by score â†’ return top 5

**Confidence from reranker scores:** `>5.0` = high, `>0.0` = medium, otherwise = low.

**Fallback:** If anything fails, falls back to basic vector search so the API never returns an error.

---

### `backend/app/live_context.py`
**Role:** Enriches the RAG context with real-time data from three public medical APIs.

**Called:** Once per query, after hybrid retrieval. Hard timeout: **2.5 seconds** for all three calls combined.

**Three concurrent fetches:**

1. **PubMed** (`fetch_pubmed_abstracts`):
   - eSearch: finds up to 3 relevant PMIDs for the query
   - eFetch: retrieves abstract text
   - Returns first 1200 chars of abstracts

2. **RxNorm** (`fetch_drug_interactions`):
   - Extracts drug names from query using `extract_drug_names()` (known-drugs lookup + suffix heuristic)
   - If â‰¥2 drugs found: queries RxNorm interaction list
   - Returns up to 3 interaction descriptions with severity ratings

3. **OpenFDA** (`fetch_fda_adverse_events`):
   - If any drug detected: queries FDA adverse event database
   - Returns top 5 reported adverse reactions for that drug

**Design:** All failures are silently swallowed. The main response is never blocked by live context. If all three fail, returns empty string and RAG-only context is used.

---

### `backend/app/lab_reference.py`
**Role:** Reference ranges for 60+ lab tests and a parser for extracted lab text.

**`LAB_REFERENCE_RANGES`:** Dictionary mapping canonical test name â†’ `(unit, normal_low, normal_high, critical_low, critical_high)` for:
- CBC (hemoglobin, WBC, platelets, differentials, MCV, MCH, MCHC, RDW)
- Basic/Comprehensive Metabolic Panel (sodium, potassium, BUN, creatinine, glucose, calcium, etc.)
- Lipid Panel (cholesterol, LDL, HDL, triglycerides, VLDL)
- Liver Function Tests (ALT/SGPT, AST/SGOT, ALP, GGT, bilirubin, albumin)
- Thyroid Panel (TSH, Free T4, Free T3, T3/T4 total)
- Kidney (uric acid, eGFR, urea)
- Diabetes (HbA1c, fasting glucose, random glucose)
- Coagulation (PT, INR, APTT, fibrinogen)
- Other (PSA, ESR, CRP, ferritin, iron, vitamin B12, folate, vitamin D, amylase, lipase, troponin, BNP, D-dimer)

**`LAB_ALIASES`:** Maps 100+ alternate names and abbreviations to canonical keys (e.g., "SGPT" â†’ "alt", "HbA1c" â†’ "hba1c").

**`parse_lab_text(extracted_text)`:** Line-by-line regex parser. Each line: `TEST_NAME VALUE UNIT`. Normalizes name, parses numeric value, classifies status, deduplicates. Returns list of dicts.

**`format_lab_table_as_context(lab_values)`:** Formats parsed values into a fixed-width text table with highlighted abnormal/critical values, ready to be injected into the LLM prompt.

---

### `backend/app/safety.py`
**Role:** Content moderation with a two-tier emergency detection system.

**Tier 1 â€” Keyword Pre-screen (`check_emergency_keywords`):**
- Scans message for 50+ keywords across categories: suicide/self-harm, cardiac, stroke, breathing, bleeding, consciousness, poisoning, allergic reaction, seizures, etc.
- Fast, runs in microseconds.

**Tier 2 â€” LLM Context Assessment (`assess_emergency_context`):**
- Only runs if Tier 1 triggers (reduces cost and latency for normal queries).
- Asks LLaMA to classify as `ACTIVE_EMERGENCY`, `NOT_EMERGENCY`, or `UNCLEAR`.
- Distinguishes: "I'm having chest pain NOW" (ACTIVE) vs "I had chest pain last week" (NOT).
- If `UNCLEAR`, defaults to `ACTIVE_EMERGENCY` for safety.

**Other checks:**
- `check_inappropriate_content()` â€” Blocks hack/exploit/weapon/suicide method requests.
- `check_mental_health()` â€” Detects anxiety, depression, PTSD, etc. â†’ prepends a compassionate preamble with crisis hotlines (does NOT block the query).
- `validate_message_length()` â€” 3â€“2000 character bounds.

**Emergency response:** Shows Indian emergency numbers (108, 102, 100, 112) and crisis hotlines (iCall, Vandrevala Foundation, AASRA).

---

### `backend/app/triage.py`
**Role:** Classifies query urgency into 5 clinical levels for display on the frontend.

**Levels:**
- ğŸ”´ `EMERGENCY` â€” life-threatening NOW, call 108 immediately
- ğŸŸ  `URGENT` â€” see doctor within 24 hours
- ğŸŸ¡ `SEMI_URGENT` â€” see doctor within 1-3 days
- ğŸŸ¢ `ROUTINE` â€” self-care appropriate
- ğŸ”µ `INFO` â€” general question, no active symptoms

Each level has a color hex, label, and icon. The response includes a `reason` sentence explaining the classification. Defaults to `ROUTINE` on LLM error.

---

### `backend/app/auth.py`
**Role:** Password security and JWT token management.

- `hash_password(password)` â€” bcrypt hashing via `passlib.CryptContext`
- `verify_password(plain, hashed)` â€” constant-time bcrypt comparison
- `create_access_token(data)` â€” Creates HS256 JWT with 24-hour expiry. Payload: `{"sub": user_id, "exp": ...}`

**Secret key:** Read from `JWT_SECRET` env var. Falls back to `"your-fallback-secret"` (insecure; always set in production).

---

### `backend/app/database.py`
**Role:** MongoDB Atlas connection management.

- Uses `motor.motor_asyncio.AsyncIOMotorClient` for fully async MongoDB operations.
- Connects with `ServerApi('1')`, TLS enabled, `certifi` CA bundle for SSL certificate verification.
- Pool settings: `maxPoolSize=10`, `minPoolSize=1`, `retryWrites=True`.
- `get_collection(name)` â€” Returns a collection from the `medical_chatbot` database.

**Singleton:** `db_service = MongoDB()` â€” connection established once at startup via `lifespan`.

---

## 6. Frontend â€” File-by-File Description

---

### `frontend/src/main.jsx`
Entry point. Mounts `<App />` into `#root` in `index.html`. Standard React 18 `createRoot`.

---

### `frontend/src/App.jsx`
**Role:** Root component and state manager. Contains all business logic for the UI.

**State managed:**
| State | Type | Purpose |
|-------|------|---------|
| `user` | object/null | Logged-in user info (from localStorage) |
| `conversations` | array | Sidebar chat list |
| `currentChatId` | string/null | Active chat MongoDB ObjectId |
| `messages` | array | Current chat message list |
| `awaitingFollowup` | bool | Whether next send is Turn 2 |
| `loading` | bool | Disables input during API call |
| `selectedLanguage` | string | ISO code for translation (default "en") |
| `sidebarOpen` | bool | Sidebar toggle state |
| `showHealthProfile` | bool | Health profile modal visibility |
| `selectedImage` | File/null | Pending image upload |
| `selectedLabFile` | File/null | Pending lab file upload |
| `showLabModal` | bool | Lab context modal visibility |
| `showSymptomChecker` | bool | Symptom checker modal visibility |

**Key handlers:**
- `handleSendMessage()` â€” Translates if needed, sends to SSE stream, updates UI token-by-token
- `handleSendWithImage()` â€” Reads image as base64 for preview, sends multipart to `/chat/image`
- `handleSendLabResults()` â€” Sends lab file + context to `/chat/lab-results`, renders lab value table
- `handleSimplify()` â€” Extracts last assistant message, posts to `/simplify`, appends result
- `handleFindHospitals()` â€” Uses `navigator.geolocation` + keyword mapping to open Google Maps
- `formatMedicalResponse()` â€” Parses `**Section Headers**` from LLM output into structured section objects for `ChatMessage` to render with icons

---

### `frontend/src/services/api.js`
**Role:** All network communication. Single source of truth for API calls.

- Creates an **axios instance** with base URL from `VITE_API_URL` env var, 60-second timeout.
- **Request interceptor:** Reads `medicore_token` from localStorage, adds `Authorization: Bearer` header.
- **Response interceptor:** On 401, clears auth data and reloads page to show login.
- **`sendMessageStream()`** â€” Uses native `fetch` + `ReadableStream` to consume SSE events (`chat_id`, `content`, `triage`, `done`, `error`). Calls `onChunk(text)` callback for each content event.

---

### `frontend/src/components/AuthScreen.jsx`
Login and signup form. Toggles between login/signup mode. Calls `api.login()` or `api.signup()`, calls `onLogin(userData)` callback on success. Displays field-level error messages.

---

### `frontend/src/components/Sidebar.jsx`
Left panel with:
- "New Chat" button
- Scrollable list of past conversations (title, timestamp)
- Delete button per conversation
- User name + email display
- Logout button

Styled with `Sidebar.css`.

---

### `frontend/src/components/ChatMessage.jsx`
Renders a single message bubble. For assistant messages:
- If `formatted` (parsed sections array): renders each section with icon + header + content
- Otherwise: renders raw text
- Shows `TriageBadge` if `triage` data present
- Shows `ConfidenceBadge` if `confidence` data present
- Shows `FeedbackButtons` for thumbs up/down
- Shows lab value table with colored status badges if `isLabResult=true`
- Shows image preview thumbnail if `imageUrl` present
- Streaming: renders character-by-character as SSE chunks arrive

---

### `frontend/src/components/ChatInput.jsx`
Single-line text input. Sends on Enter (without Shift). Passes message text up via `onSend` callback. Clears after send.

---

### `frontend/src/components/VoiceControls.jsx`
Web Speech API integration. Mic button â†’ starts `SpeechRecognition`. On result, calls `onSend` with transcribed text. Language-aware (uses `selectedLanguage` to set recognition language).

---

### `frontend/src/components/LanguageSelector.jsx`
Dropdown for 12 languages: English, Spanish, French, German, Chinese, Arabic, Hindi, Tamil, Telugu, Marathi, Bengali, Kannada. Sets `selectedLanguage` state in App.

---

### `frontend/src/components/HealthProfileForm.jsx`
Modal form for entering: age, sex, height/weight, blood type, known conditions, medications, allergies, family history, lifestyle (smoking, alcohol, exercise). Calls `api.getHealthProfile()` on mount to pre-fill. Saves with `api.updateHealthProfile()`.

---

### `frontend/src/components/SymptomChecker.jsx`
Guided wizard that walks the user through selecting symptoms by body system (head, chest, abdomen, etc.). Generates a natural language query and calls `onSend()` to submit it as a regular chat message.

---

### `frontend/src/components/LabUploadModal.jsx`
Modal that appears after a lab file is selected. Lets user add optional context notes (e.g., "patient age 45, diabetic"). On confirm, passes file + context to `handleSendLabResults()`.

---

### `frontend/src/components/ExportChatPDF.jsx`
Generates a PDF of the current conversation using the browser's print API. Formats messages with styling for clean PDF output.

---

### `frontend/src/components/TriageBadge.jsx`
Renders a colored pill badge showing triage level (ğŸ”´ Emergency / ğŸŸ  Urgent / ğŸŸ¡ Semi-Urgent / ğŸŸ¢ Routine / ğŸ”µ Informational) with the LLM's one-sentence reason.

---

### `frontend/src/components/ConfidenceBadge.jsx`
Renders a small badge showing RAG retrieval confidence: High / Medium / Low, indicating how well the knowledge base matched the query.

---

### `frontend/src/components/FeedbackButtons.jsx`
Thumbs up / thumbs down buttons on each assistant response. Calls `api.submitFeedback()` with `rating: 1` or `rating: -1`. Shows confirmation after submission.

---

### `frontend/src/components/LoadingSpinner.jsx`
Animated spinner displayed in the chat area while waiting for a response.

---

## 7. Data Ingestion Pipeline

**File:** `backend/ingestion/rag_setup.py`

**Purpose:** One-time script run before the first deployment to populate the Pinecone index. Not part of the live API.

**Process:**
```
5 PDF volumes (Gale Encyclopedia of Medicine)
        â”‚
        â–¼ PyMuPDFLoader (LangChain community)
        â”‚  Loads each page as a Document
        â”‚
        â–¼ deduplicate_documents()
        â”‚  MD5 hash of page content â†’ remove duplicates
        â”‚
        â–¼ RecursiveCharacterTextSplitter
        â”‚  chunk_size=1000, chunk_overlap=200
        â”‚  â†’ ~500,000+ text chunks
        â”‚
        â–¼ HuggingFaceEmbeddings
        â”‚  Model: pritamdeka/S-PubMedBert-MS-MARCO
        â”‚  768-dimensional vectors
        â”‚  Batch processing to manage RAM
        â”‚
        â–¼ Pinecone.upsert()
        â”‚  Index name: medicore-ai
        â”‚  Checkpoint file: ingestion_checkpoint.json
        â”‚  (resumable if interrupted)
        â”‚
        â–¼ Pinecone index ready for retrieval
```

**`fetch_web_sources.py`** â€” Optional companion script that scrapes WHO/CDC web pages using BeautifulSoup and adds those chunks to the Pinecone index for additional coverage.

---

## 8. MongoDB Collections

| Collection | Fields | Purpose |
|-----------|--------|---------|
| `users` | `email`, `password` (hashed), `name`, `created_at`, `updated_at` | User accounts |
| `chats` | `user_id`, `title`, `messages[]` (role+content), `created_at`, `updated_at` | Conversation history |
| `chat_summaries` | `user_id`, `chat_id`, `summary`, `created_at` | Cross-session memory (LLM-generated summaries) |
| `health_profiles` | `user_id`, `age`, `sex`, `height_cm`, `weight_kg`, `blood_type`, `known_conditions[]`, `current_medications[]`, `allergies[]`, `family_history[]`, `smoking`, `alcohol`, `exercise` | User health context for personalized responses |
| `feedback` | `user_id`, `chat_id`, `message_index`, `rating` (-1/1), `comment`, `created_at` | Thumbs up/down ratings |

---

## 9. API Endpoint Reference

```
Base URL: http://localhost:8000

Auth:
  POST   /api/auth/signup          Body: { email, password, name }
  POST   /api/auth/login           Body: { email, password }
  POST   /api/auth/logout          Header: Bearer token

Chat:
  POST   /api/chat/new             â†’ { chat_id, message }
  GET    /api/chat/history         â†’ { chats: [...] }
  GET    /api/chat/{chat_id}       â†’ { chat_id, title, messages, ... }
  DELETE /api/chat/{chat_id}       â†’ { message }
  POST   /api/chat                 Body: { message, chat_id?, awaiting_followup }
                                   â†’ { response, awaiting_followup, sources, chat_id, confidence, triage }
  POST   /api/chat/stream          Body: same as /chat
                                   â†’ SSE stream of { type: chat_id|content|triage|done|error }
  POST   /api/chat/image           Multipart: image file + message + chat_id?
                                   â†’ { response, chat_id, confidence, sources }
  POST   /api/chat/lab-results     Multipart: file + context + chat_id?
                                   â†’ { lab_values[], interpretation, chat_id, raw_extracted_text, sources }

Utilities:
  POST   /api/simplify             Body: { chat_history: [...] }
  POST   /api/translate            Body: { text, target_language, source_language? }
  POST   /api/detect-language      Body: { text }

Profile:
  POST   /api/profile              Body: health profile fields
  GET    /api/profile              â†’ health profile
  DELETE /api/profile

Feedback:
  POST   /api/feedback             Body: { chat_id, message_index, rating, comment? }

System:
  GET    /                         â†’ API info
  GET    /health                   â†’ { status, mongodb, vector_store }
  GET    /api/test                 â†’ endpoint list
  GET    /api/debug/mongodb        â†’ MongoDB connection test
```

---

## 10. Environment Variables

### `backend/.env`

| Variable | Required | Description |
|----------|----------|-------------|
| `GROQ_API_KEY` | Yes | Groq cloud API key for LLaMA |
| `PINECONE_API_KEY` | Yes | Pinecone cloud API key |
| `PINECONE_INDEX_NAME` | No | Index name (default: `medicore-ai`) |
| `MONGODB_URI` | Yes | MongoDB Atlas connection string |
| `JWT_SECRET` | Yes | Secret key for signing JWTs (use a long random string) |
| `EMBEDDING_MODEL` | No | HuggingFace model name (default: `pritamdeka/S-PubMedBert-MS-MARCO`) |
| `CORS_ORIGINS` | No | Comma-separated allowed origins (default: `http://localhost:5173,http://localhost:3000`) |

### `frontend/.env`

| Variable | Required | Description |
|----------|----------|-------------|
| `VITE_API_URL` | No | Backend URL (default: `http://localhost:8000`) |

---

## 11. Key Design Decisions

### Two-Turn Conversation
Rather than answering vague queries with generic information, the system first assesses query specificity. For vague queries ("my stomach hurts"), it asks one focused clinical question, then uses both the original query and follow-up answer to retrieve much more targeted context. This significantly improves response quality.

### Hybrid Retrieval
Pure vector search can miss exact medical terms (drug names, test abbreviations). Pure BM25 misses semantic similarity. The hybrid approach with RRF fusion and cross-encoder reranking gives the best of both: semantic understanding + keyword precision, then final relevance scoring.

### PubMedBERT Embeddings
General-purpose embeddings (like OpenAI's `text-embedding-ada-002`) are not optimized for medical text. PubMedBERT was pretrained on PubMed abstracts and MS MARCO, making it significantly better at medical terminology. **Critical requirement:** the same model must be used at both ingestion time and query time.

### Live Context with Hard Timeout
Static RAG can go stale. Real-time PubMed, RxNorm, and FDA data adds recency without blocking the response. The 2.5-second timeout ensures live context never degrades user experience â€” it's always best-effort.

### Two-Tier Emergency Detection
A simple keyword scan ("chest pain") would trigger emergency alerts for queries like "What causes chest pain?" or "My grandmother had chest pain last week." The two-tier system uses LLM context to distinguish active emergencies from informational queries, dramatically reducing false positives while maintaining safety for true emergencies.

### Cross-Session Memory
JWT is stateless, so session data isn't inherently persisted. After each conversation, a background task summarizes the key medical topics discussed and stores that summary. On the next session, those summaries are injected into the LLM context, allowing the assistant to reference what was discussed previously without storing full conversation history in the prompt.

### Streaming (SSE)
For a 1500-token response at LLaMA speeds, non-streaming would mean 5-15 seconds of blank screen. SSE streaming delivers tokens as they're generated, making the interaction feel instant. The SSE protocol also allows sending structured metadata events (`chat_id`, `triage`, `done`) alongside content chunks.

### Singleton Services
`llm_service`, `retriever_service`, `hybrid_retriever_service`, and `db_service` are all module-level singletons. The embedding model and cross-encoder are loaded once at startup (taking 10-60 seconds) and reused across all requests. This is critical for performance â€” loading a transformer model per request would be unusable.
